{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Modeling\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/gulyagurbanova/Desktop/uom/extended research/data/processed_reviews_second.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in each topic for the LDA model with 13 topics:\n",
      "Topic 1: ['back', 'place', 'everything', 'come', 'definitely', 'would', 'apartment', 'perfect', 'amaze', 'location']\n",
      "Topic 2: ['easy', 'great', 'place', 'access', 'check', 'good', 'apartment', 'clean', 'location', 'get']\n",
      "Topic 3: ['host', 'you', 'give', 'time', 'even', 'check', 'get', 'go', 'day', 'early']\n",
      "Topic 4: ['recommend', 'would', 'highly', 'definitely', 'place', 'great', 'apartment', 'location', 'clean', 'lovely']\n",
      "Topic 5: ['floor', 'top', 'building', 'unit', 'luggage', 'response', 'problem', 'ground', 'old', 'lift']\n",
      "Topic 6: ['host', 'room', 'friendly', 'place', 'nice', 'clean', 'really', 'house', 'comfortable', 'helpful']\n",
      "Topic 7: ['host', 'great', 'apartment', 'location', 'helpful', 'responsive', 'excellent', 'clean', 'everything', 'communication']\n",
      "Topic 8: ['apartment', 'room', 'kitchen', 'good', 'bit', 'would', 'night', 'bathroom', 'bed', 'location']\n",
      "Topic 9: ['bus', 'walk', 'stop', 'tram', 'quick', 'get', 'airport', 'away', 'easy', 'min']\n",
      "Topic 10: ['stayed', 'night', 'best', 'one', 'far', 'place', 'enough', 'weekend', 'ever', 'two']\n",
      "Topic 11: ['walk', 'town', 'apartment', 'distance', 'great', 'location', 'within', 'old', 'mile', 'station']\n",
      "Topic 12: ['home', 'host', 'make', 'felt', 'like', 'feel', 'welcome', 'you', 'coffee', 'tea']\n",
      "Topic 13: ['apartment', 'great', 'location', 'comfortable', 'well', 'lovely', 'parking', 'clean', 'space', 'quiet']\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing the text data\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2)\n",
    "dtm = vectorizer.fit_transform(df['comments'])\n",
    "\n",
    "# Converting the document-term matrix to a gensim corpus\n",
    "corpus = gensim.matutils.Sparse2Corpus(dtm, documents_columns=False)\n",
    "id2word = {v: k for k, v in vectorizer.vocabulary_.items()}\n",
    "\n",
    "# Creating a gensim dictionary from the corpus\n",
    "dictionary = corpora.Dictionary.from_corpus(corpus, id2word=id2word)\n",
    "\n",
    "# Building the LDA Model with 13 Topics\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=13, random_state=42, passes=10)\n",
    "\n",
    "# Displaying key words for each topic\n",
    "num_words = 10  \n",
    "\n",
    "print(\"Top words in each topic for the LDA model with 13 topics:\")\n",
    "for i in range(13):  # Loop through each topic index from 0 to 12\n",
    "    topic = lda_model.show_topic(i, num_words)\n",
    "    print(f\"Topic {i + 1}: {[word for word, _ in topic]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
